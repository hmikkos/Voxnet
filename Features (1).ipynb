{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import Utilitaires\n",
    "\n",
    "class VoxNet_feat(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_shape=(32, 32, 32)): \n",
    "        super(VoxNet_feat, self).__init__()\n",
    "        self.conv = torch.nn.Sequential(torch.nn.Conv3d(1,32,5,2),\n",
    "                                       torch.nn.LeakyReLU(),\n",
    "                                       torch.nn.Dropout(p=0.2),\n",
    "                                       torch.nn.Conv3d(32, 32, 3),\n",
    "                                       torch.nn.LeakyReLU(),\n",
    "                                       torch.nn.MaxPool3d(2),\n",
    "                                       torch.nn.Dropout(p=0.3)\n",
    "                                       \n",
    "        )\n",
    "        self.fc1=torch.nn.Linear(32* 6 * 6 * 6, 128)\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.4),\n",
    "            torch.nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=x.view(x.size()[0],1,32,32,32)\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6978\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "num_classes=10\n",
    "_,trainset=Utilitaires.txt_to_tensordataset('train2.txt',num_classes)\n",
    "_,testset=Utilitaires.txt_to_tensordataset('test2.txt',num_classes)\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True,num_workers=0)\n",
    "testloader=torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True,num_workers=0)\n",
    "print(len(testloader.dataset))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n",
      "[1,    10] loss: 0.054\n",
      "[1,    10] acc: 0.303\n",
      "[1,    20] loss: 0.035\n",
      "[1,    20] acc: 0.579\n",
      "[1,    30] loss: 0.031\n",
      "[1,    30] acc: 0.593\n",
      "[1,    40] loss: 0.023\n",
      "[1,    40] acc: 0.680\n",
      "[1,    50] loss: 0.020\n",
      "[1,    50] acc: 0.671\n",
      "[1,    60] loss: 0.020\n",
      "[1,    60] acc: 0.701\n",
      "[1,    70] loss: 0.018\n",
      "[1,    70] acc: 0.688\n",
      "[1,    80] loss: 0.012\n",
      "[1,    80] acc: 0.757\n",
      "[1,    90] loss: 0.014\n",
      "[1,    90] acc: 0.753\n",
      "[1,   100] loss: 0.014\n",
      "[1,   100] acc: 0.754\n",
      "[1,   110] loss: 0.014\n",
      "[1,   110] acc: 0.763\n",
      "[1,   120] loss: 0.013\n",
      "[1,   120] acc: 0.765\n",
      "[1,   130] loss: 0.008\n",
      "[1,   130] acc: 0.809\n",
      "[1,   140] loss: 0.012\n",
      "[1,   140] acc: 0.781\n",
      "[1,   150] loss: 0.006\n",
      "[1,   150] acc: 0.843\n",
      "[1,   160] loss: 0.008\n",
      "[1,   160] acc: 0.805\n",
      "[1,   170] loss: 0.009\n",
      "[1,   170] acc: 0.805\n",
      "[1,   180] loss: 0.009\n",
      "[1,   180] acc: 0.797\n",
      "[1,   190] loss: 0.013\n",
      "[1,   190] acc: 0.761\n",
      "[1,   200] loss: 0.011\n",
      "[1,   200] acc: 0.801\n",
      "[1,   210] loss: 0.008\n",
      "[1,   210] acc: 0.796\n",
      "[1,   220] loss: 0.007\n",
      "[1,   220] acc: 0.825\n",
      "[1,   230] loss: 0.009\n",
      "[1,   230] acc: 0.801\n",
      "[1,   240] loss: 0.008\n",
      "[1,   240] acc: 0.799\n",
      "[1,   250] loss: 0.007\n",
      "[1,   250] acc: 0.833\n",
      "[1,   260] loss: 0.008\n",
      "[1,   260] acc: 0.803\n",
      "[1,   270] loss: 0.007\n",
      "[1,   270] acc: 0.830\n",
      "[1,   280] loss: 0.008\n",
      "[1,   280] acc: 0.806\n",
      "[1,   290] loss: 0.006\n",
      "[1,   290] acc: 0.832\n",
      "[1,   300] loss: 0.005\n",
      "[1,   300] acc: 0.829\n",
      "[1,   310] loss: 0.006\n",
      "[1,   310] acc: 0.836\n",
      "[1,   320] loss: 0.005\n",
      "[1,   320] acc: 0.843\n",
      "[1,   330] loss: 0.006\n",
      "[1,   330] acc: 0.801\n",
      "[1,   340] loss: 0.006\n",
      "[1,   340] acc: 0.815\n",
      "[1,   350] loss: 0.006\n",
      "[1,   350] acc: 0.824\n",
      "[1,   360] loss: 0.007\n",
      "[1,   360] acc: 0.809\n",
      "[1,   370] loss: 0.007\n",
      "[1,   370] acc: 0.814\n",
      "[1,   380] loss: 0.008\n",
      "[1,   380] acc: 0.801\n",
      "[1,   390] loss: 0.006\n",
      "[1,   390] acc: 0.827\n",
      "[1,   400] loss: 0.006\n",
      "[1,   400] acc: 0.806\n",
      "[1,   410] loss: 0.004\n",
      "[1,   410] acc: 0.863\n",
      "[1,   420] loss: 0.006\n",
      "[1,   420] acc: 0.827\n",
      "[1,   430] loss: 0.005\n",
      "[1,   430] acc: 0.836\n",
      "[1,   440] loss: 0.004\n",
      "[1,   440] acc: 0.858\n",
      "[1,   450] loss: 0.005\n",
      "[1,   450] acc: 0.811\n",
      "[1,   460] loss: 0.007\n",
      "[1,   460] acc: 0.806\n",
      "[1,   470] loss: 0.009\n",
      "[1,   470] acc: 0.786\n",
      "[1,   480] loss: 0.007\n",
      "[1,   480] acc: 0.834\n",
      "[1,   490] loss: 0.008\n",
      "[1,   490] acc: 0.814\n",
      "[1,   500] loss: 0.006\n",
      "[1,   500] acc: 0.818\n",
      "[1,   510] loss: 0.004\n",
      "[1,   510] acc: 0.846\n",
      "[1,   520] loss: 0.007\n",
      "[1,   520] acc: 0.810\n",
      "[1,   530] loss: 0.006\n",
      "[1,   530] acc: 0.824\n",
      "[1,   540] loss: 0.005\n",
      "[1,   540] acc: 0.834\n",
      "[1,   550] loss: 0.005\n",
      "[1,   550] acc: 0.841\n",
      "[1,   560] loss: 0.007\n",
      "[1,   560] acc: 0.805\n",
      "[1,   570] loss: 0.004\n",
      "[1,   570] acc: 0.835\n",
      "[1,   580] loss: 0.007\n",
      "[1,   580] acc: 0.829\n",
      "[1,   590] loss: 0.004\n",
      "[1,   590] acc: 0.847\n",
      "[1,   600] loss: 0.004\n",
      "[1,   600] acc: 0.840\n",
      "[1,   610] loss: 0.004\n",
      "[1,   610] acc: 0.841\n",
      "[1,   620] loss: 0.004\n",
      "[1,   620] acc: 0.864\n",
      "[1,   630] loss: 0.003\n",
      "[1,   630] acc: 0.865\n",
      "[1,   640] loss: 0.004\n",
      "[1,   640] acc: 0.846\n",
      "[1,   650] loss: 0.004\n",
      "[1,   650] acc: 0.857\n",
      "[1,   660] loss: 0.004\n",
      "[1,   660] acc: 0.842\n",
      "[1,   670] loss: 0.005\n",
      "[1,   670] acc: 0.827\n",
      "[1,   680] loss: 0.007\n",
      "[1,   680] acc: 0.841\n",
      "[1,   690] loss: 0.003\n",
      "[1,   690] acc: 0.841\n",
      "[1,   700] loss: 0.004\n",
      "[1,   700] acc: 0.834\n",
      "[1,   710] loss: 0.005\n",
      "[1,   710] acc: 0.835\n",
      "[1,   720] loss: 0.004\n",
      "[1,   720] acc: 0.850\n",
      "[1,   730] loss: 0.003\n",
      "[1,   730] acc: 0.855\n",
      "[1,   740] loss: 0.006\n",
      "[1,   740] acc: 0.810\n",
      "[1,   750] loss: 0.006\n",
      "[1,   750] acc: 0.834\n",
      "[1,   760] loss: 0.005\n",
      "[1,   760] acc: 0.848\n",
      "[1,   770] loss: 0.005\n",
      "[1,   770] acc: 0.833\n",
      "[1,   780] loss: 0.005\n",
      "[1,   780] acc: 0.841\n",
      "[1,   790] loss: 0.005\n",
      "[1,   790] acc: 0.836\n",
      "[1,   800] loss: 0.002\n",
      "[1,   800] acc: 0.875\n",
      "[1,   810] loss: 0.005\n",
      "[1,   810] acc: 0.848\n",
      "[1,   820] loss: 0.005\n",
      "[1,   820] acc: 0.828\n",
      "[1,   830] loss: 0.004\n",
      "[1,   830] acc: 0.844\n",
      "[1,   840] loss: 0.003\n",
      "[1,   840] acc: 0.851\n",
      "[1,   850] loss: 0.005\n",
      "[1,   850] acc: 0.840\n",
      "[1,   860] loss: 0.004\n",
      "[1,   860] acc: 0.849\n",
      "[1,   870] loss: 0.006\n",
      "[1,   870] acc: 0.851\n",
      "[1,   880] loss: 0.006\n",
      "[1,   880] acc: 0.844\n",
      "[1,   890] loss: 0.002\n",
      "[1,   890] acc: 0.868\n",
      "[1,   900] loss: 0.002\n",
      "[1,   900] acc: 0.862\n",
      "[1,   910] loss: 0.003\n",
      "[1,   910] acc: 0.840\n",
      "[1,   920] loss: 0.003\n",
      "[1,   920] acc: 0.848\n",
      "[1,   930] loss: 0.002\n",
      "[1,   930] acc: 0.869\n",
      "[1,   940] loss: 0.004\n",
      "[1,   940] acc: 0.852\n",
      "[1,   950] loss: 0.003\n",
      "[1,   950] acc: 0.847\n",
      "[1,   960] loss: 0.002\n",
      "[1,   960] acc: 0.856\n",
      "[1,   970] loss: 0.002\n",
      "[1,   970] acc: 0.860\n",
      "[1,   980] loss: 0.004\n",
      "[1,   980] acc: 0.850\n",
      "[1,   990] loss: 0.005\n",
      "[1,   990] acc: 0.843\n",
      "[1,  1000] loss: 0.004\n",
      "[1,  1000] acc: 0.830\n",
      "[1,  1010] loss: 0.005\n",
      "[1,  1010] acc: 0.849\n",
      "[1,  1020] loss: 0.002\n",
      "[1,  1020] acc: 0.868\n",
      "[1,  1030] loss: 0.004\n",
      "[1,  1030] acc: 0.857\n",
      "[1,  1040] loss: 0.002\n",
      "[1,  1040] acc: 0.865\n",
      "[1,  1050] loss: 0.003\n",
      "[1,  1050] acc: 0.848\n",
      "[2,    10] loss: 0.001\n",
      "[2,    10] acc: 0.856\n",
      "[2,    20] loss: 0.003\n",
      "[2,    20] acc: 0.861\n",
      "[2,    30] loss: 0.002\n",
      "[2,    30] acc: 0.871\n",
      "[2,    40] loss: 0.005\n",
      "[2,    40] acc: 0.859\n",
      "[2,    50] loss: 0.003\n",
      "[2,    50] acc: 0.852\n",
      "[2,    60] loss: 0.003\n",
      "[2,    60] acc: 0.859\n",
      "[2,    70] loss: 0.002\n",
      "[2,    70] acc: 0.860\n",
      "[2,    80] loss: 0.003\n",
      "[2,    80] acc: 0.859\n",
      "[2,    90] loss: 0.002\n",
      "[2,    90] acc: 0.868\n",
      "[2,   100] loss: 0.001\n",
      "[2,   100] acc: 0.867\n",
      "[2,   110] loss: 0.002\n",
      "[2,   110] acc: 0.868\n",
      "[2,   120] loss: 0.002\n",
      "[2,   120] acc: 0.866\n",
      "[2,   130] loss: 0.003\n",
      "[2,   130] acc: 0.850\n",
      "[2,   140] loss: 0.002\n",
      "[2,   140] acc: 0.863\n",
      "[2,   150] loss: 0.003\n",
      "[2,   150] acc: 0.855\n",
      "[2,   160] loss: 0.004\n",
      "[2,   160] acc: 0.850\n",
      "[2,   170] loss: 0.003\n",
      "[2,   170] acc: 0.857\n",
      "[2,   180] loss: 0.003\n",
      "[2,   180] acc: 0.843\n",
      "[2,   190] loss: 0.003\n",
      "[2,   190] acc: 0.861\n",
      "[2,   200] loss: 0.005\n",
      "[2,   200] acc: 0.840\n",
      "[2,   210] loss: 0.002\n",
      "[2,   210] acc: 0.868\n",
      "[2,   220] loss: 0.005\n",
      "[2,   220] acc: 0.847\n",
      "[2,   230] loss: 0.001\n",
      "[2,   230] acc: 0.869\n",
      "[2,   240] loss: 0.001\n",
      "[2,   240] acc: 0.877\n",
      "[2,   250] loss: 0.005\n",
      "[2,   250] acc: 0.851\n",
      "[2,   260] loss: 0.001\n",
      "[2,   260] acc: 0.865\n",
      "[2,   270] loss: 0.004\n",
      "[2,   270] acc: 0.852\n",
      "[2,   280] loss: 0.004\n",
      "[2,   280] acc: 0.866\n",
      "[2,   290] loss: 0.003\n",
      "[2,   290] acc: 0.848\n",
      "[2,   300] loss: 0.005\n",
      "[2,   300] acc: 0.836\n",
      "[2,   310] loss: 0.003\n",
      "[2,   310] acc: 0.853\n",
      "[2,   320] loss: 0.002\n",
      "[2,   320] acc: 0.865\n",
      "[2,   330] loss: 0.005\n",
      "[2,   330] acc: 0.831\n",
      "[2,   340] loss: 0.003\n",
      "[2,   340] acc: 0.857\n",
      "[2,   350] loss: 0.004\n",
      "[2,   350] acc: 0.849\n",
      "[2,   360] loss: 0.002\n",
      "[2,   360] acc: 0.867\n",
      "[2,   370] loss: 0.001\n",
      "[2,   370] acc: 0.865\n",
      "[2,   380] loss: 0.003\n",
      "[2,   380] acc: 0.856\n",
      "[2,   390] loss: 0.004\n",
      "[2,   390] acc: 0.858\n",
      "[2,   400] loss: 0.004\n",
      "[2,   400] acc: 0.835\n",
      "[2,   410] loss: 0.002\n",
      "[2,   410] acc: 0.861\n",
      "[2,   420] loss: 0.003\n",
      "[2,   420] acc: 0.851\n",
      "[2,   430] loss: 0.001\n",
      "[2,   430] acc: 0.873\n",
      "[2,   440] loss: 0.003\n",
      "[2,   440] acc: 0.848\n",
      "[2,   450] loss: 0.004\n",
      "[2,   450] acc: 0.838\n",
      "[2,   460] loss: 0.001\n",
      "[2,   460] acc: 0.864\n",
      "[2,   470] loss: 0.005\n",
      "[2,   470] acc: 0.850\n",
      "[2,   480] loss: 0.003\n",
      "[2,   480] acc: 0.856\n",
      "[2,   490] loss: 0.002\n",
      "[2,   490] acc: 0.861\n",
      "[2,   500] loss: 0.002\n",
      "[2,   500] acc: 0.862\n",
      "[2,   510] loss: 0.002\n",
      "[2,   510] acc: 0.871\n",
      "[2,   520] loss: 0.002\n",
      "[2,   520] acc: 0.868\n",
      "[2,   530] loss: 0.004\n",
      "[2,   530] acc: 0.848\n",
      "[2,   540] loss: 0.002\n",
      "[2,   540] acc: 0.870\n",
      "[2,   550] loss: 0.003\n",
      "[2,   550] acc: 0.862\n",
      "[2,   560] loss: 0.001\n",
      "[2,   560] acc: 0.864\n",
      "[2,   570] loss: 0.004\n",
      "[2,   570] acc: 0.844\n",
      "[2,   580] loss: 0.002\n",
      "[2,   580] acc: 0.868\n",
      "[2,   590] loss: 0.005\n",
      "[2,   590] acc: 0.837\n",
      "[2,   600] loss: 0.004\n",
      "[2,   600] acc: 0.840\n",
      "[2,   610] loss: 0.003\n",
      "[2,   610] acc: 0.841\n",
      "[2,   620] loss: 0.003\n",
      "[2,   620] acc: 0.861\n",
      "[2,   630] loss: 0.006\n",
      "[2,   630] acc: 0.828\n",
      "[2,   640] loss: 0.003\n",
      "[2,   640] acc: 0.867\n",
      "[2,   650] loss: 0.002\n",
      "[2,   650] acc: 0.859\n",
      "[2,   660] loss: 0.004\n",
      "[2,   660] acc: 0.844\n",
      "[2,   670] loss: 0.003\n",
      "[2,   670] acc: 0.844\n",
      "[2,   680] loss: 0.003\n",
      "[2,   680] acc: 0.859\n",
      "[2,   690] loss: 0.001\n",
      "[2,   690] acc: 0.867\n",
      "[2,   700] loss: 0.003\n",
      "[2,   700] acc: 0.842\n",
      "[2,   710] loss: 0.002\n",
      "[2,   710] acc: 0.864\n",
      "[2,   720] loss: 0.002\n",
      "[2,   720] acc: 0.850\n",
      "[2,   730] loss: 0.003\n",
      "[2,   730] acc: 0.841\n",
      "[2,   740] loss: 0.003\n",
      "[2,   740] acc: 0.858\n",
      "[2,   750] loss: 0.003\n",
      "[2,   750] acc: 0.856\n",
      "[2,   760] loss: 0.003\n",
      "[2,   760] acc: 0.844\n",
      "[2,   770] loss: 0.002\n",
      "[2,   770] acc: 0.858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   780] loss: 0.002\n",
      "[2,   780] acc: 0.873\n",
      "[2,   790] loss: 0.002\n",
      "[2,   790] acc: 0.866\n",
      "[2,   800] loss: 0.002\n",
      "[2,   800] acc: 0.868\n",
      "[2,   810] loss: 0.002\n",
      "[2,   810] acc: 0.859\n",
      "[2,   820] loss: 0.002\n",
      "[2,   820] acc: 0.865\n",
      "[2,   830] loss: 0.003\n",
      "[2,   830] acc: 0.849\n",
      "[2,   840] loss: 0.003\n",
      "[2,   840] acc: 0.866\n",
      "[2,   850] loss: 0.004\n",
      "[2,   850] acc: 0.848\n",
      "[2,   860] loss: 0.001\n",
      "[2,   860] acc: 0.866\n",
      "[2,   870] loss: 0.003\n",
      "[2,   870] acc: 0.858\n",
      "[2,   880] loss: 0.002\n",
      "[2,   880] acc: 0.861\n",
      "[2,   890] loss: 0.001\n",
      "[2,   890] acc: 0.873\n",
      "[2,   900] loss: 0.003\n",
      "[2,   900] acc: 0.847\n",
      "[2,   910] loss: 0.002\n",
      "[2,   910] acc: 0.869\n",
      "[2,   920] loss: 0.005\n",
      "[2,   920] acc: 0.845\n",
      "[2,   930] loss: 0.004\n",
      "[2,   930] acc: 0.859\n",
      "[2,   940] loss: 0.002\n",
      "[2,   940] acc: 0.868\n",
      "[2,   950] loss: 0.002\n",
      "[2,   950] acc: 0.864\n",
      "[2,   960] loss: 0.001\n",
      "[2,   960] acc: 0.877\n",
      "[2,   970] loss: 0.002\n",
      "[2,   970] acc: 0.847\n",
      "[2,   980] loss: 0.003\n",
      "[2,   980] acc: 0.859\n",
      "[2,   990] loss: 0.003\n",
      "[2,   990] acc: 0.856\n",
      "[2,  1000] loss: 0.002\n",
      "[2,  1000] acc: 0.864\n",
      "[2,  1010] loss: 0.003\n",
      "[2,  1010] acc: 0.869\n",
      "[2,  1020] loss: 0.002\n",
      "[2,  1020] acc: 0.868\n",
      "[2,  1030] loss: 0.002\n",
      "[2,  1030] acc: 0.873\n",
      "[2,  1040] loss: 0.001\n",
      "[2,  1040] acc: 0.872\n",
      "[2,  1050] loss: 0.001\n",
      "[2,  1050] acc: 0.873\n",
      "Finished Training\n",
      "Accuracy of the network on the loader : 96 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96.4029807967899"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "cuda=True\n",
    "net = VoxNet_feat(num_classes=num_classes)\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print(\"using cuda\")\n",
    "    net.cuda()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=learning_rate)\n",
    "Utilitaires.train(net, optimizer, trainloader, testloader, criterion,  n_epoch = 10,\n",
    "      train_acc_period = 10,\n",
    "      test_acc_period = 1000)\n",
    "Utilitaires.accuracy(net,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "labels_anglais=['airplane',\n",
    " 'bathtub',\n",
    " 'bed',\n",
    " 'bench',\n",
    " 'bookshelf',\n",
    " 'bottle',\n",
    " 'bowl',\n",
    " 'car',\n",
    " 'chair',\n",
    " 'cone',\n",
    " 'cup',\n",
    " 'curtain',\n",
    " 'desk',\n",
    " 'door',\n",
    " 'dresser',\n",
    " 'flower_pot',\n",
    " 'glass_box',\n",
    " 'guitar',\n",
    " 'keyboard',\n",
    " 'lamp',\n",
    " 'laptop',\n",
    " 'mantel',\n",
    " 'monitor',\n",
    " 'night_stand',\n",
    " 'person',\n",
    " 'piano',\n",
    " 'plant',\n",
    " 'radio',\n",
    " 'range_hood',\n",
    " 'sink',\n",
    " 'sofa',\n",
    " 'stairs',\n",
    " 'stool',\n",
    " 'table',\n",
    " 'tent',\n",
    " 'toilet',\n",
    " 'tv_stand',\n",
    " 'vase',\n",
    " 'wardrobe',\n",
    " 'xbox']\n",
    "def PCA(X, k=2):\n",
    "    X_mean = torch.mean(X,0)\n",
    "    X = X - X_mean.expand_as(X)\n",
    "    U,S,V = torch.svd(torch.t(X))\n",
    "    return torch.mm(X,U[:,:k])\n",
    "\n",
    "\n",
    "\n",
    "testloader1=torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True,num_workers=4)\n",
    "    \n",
    "\n",
    "def Feature_classification(): #classification over features from the last Fully Connected Layer ( Cf Chapter 9 of INF473V)\n",
    "    feat=torch.zeros(len(testloader1.dataset),num_classes)\n",
    "    labels=[]\n",
    "    for i, data in enumerate(testloader1, 10):\n",
    "        vol,label = data\n",
    "        label=label.item()\n",
    "        vol = vol.view(1,1,32,32,32)\n",
    "        vol = vol.type(torch.cuda.FloatTensor)\n",
    "        vol = net.conv(vol)\n",
    "        vol = vol.view(vol.size(0), -1)\n",
    "        vol = net.fc1(vol)\n",
    "        vol=net.dense(vol)\n",
    "        feat[i,:]=vol.view(num_classes)\n",
    "        labels.append(label)\n",
    "    feat=feat.detach()\n",
    "    print(feat.size())\n",
    "    feat_PCA=PCA(feat,2)\n",
    "    feat_PCA=feat_PCA.numpy()\n",
    "    X=num_classes*[[]]\n",
    "    Y=num_classes*[[]]\n",
    "    for i in range(len(labels)):\n",
    "        X[labels[i]].append(feat_PCA[i, 0])\n",
    "        Y[labels[i]].append(feat_PCA[i, 1])\n",
    "    fig = plt.figure()\n",
    "    plt.axis([-100, 100, -100, 100])\n",
    "    for j in range(num_classes):\n",
    "            plt.scatter(X[j], Y[j],label=labels_anglais[j])\n",
    "            plt.legend()\n",
    "            plt.title('PCA of ModelNet'+str(num_classes))\n",
    "            plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC1 neuron activation vs FC2 neuron activation in ModelNet10\n",
    "\n",
    "def showTensor(aTensor):\n",
    "    plt.figure()\n",
    "    plt.imshow(aTensor.detach().numpy())\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "def FC1vsFC2():\n",
    "    vol,label=testloader.dataset[100] \n",
    "    label=label.item()\n",
    "    vol = vol.view(1,1,32,32,32)\n",
    "    vol = vol.type(torch.cuda.FloatTensor)\n",
    "    vol = net.conv(vol)\n",
    "    vol = vol.view(vol.size(0), -1)\n",
    "    feature1 = net.fc1(vol)\n",
    "    feature2=net.dense(feature1)\n",
    "    feature1=feature1.cpu()\n",
    "    feature2=feature2.cpu()\n",
    "    print(feature2.size())\n",
    "    feature1=feature1.view(16,8)\n",
    "    showTensor(feature1)\n",
    "    showTensor(feature2)\n",
    "\n",
    "#FC1vsFC2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Rotation invariance\n",
    "\n",
    "_,label=testloader.dataset[0] \n",
    "label=label.item()\n",
    "print(labels_anglais[label])\n",
    "\n",
    "def show(vol):\n",
    "    vol = vol.view(1,1,32,32,32)\n",
    "    vol = vol.type(torch.cuda.FloatTensor)\n",
    "    vol = net.conv(vol)\n",
    "    vol = vol.view(vol.size(0), -1)\n",
    "    feature1 = net.fc1(vol)\n",
    "    feature2=net.dense(feature1)\n",
    "    feature1=feature1.cpu()\n",
    "    feature2=feature2.cpu()\n",
    "    feature2=feature2.view(num_classes)\n",
    "    feature1=feature1.view(128)\n",
    "    return(feature1,feature2)\n",
    "\n",
    "feat1=torch.zeros(12,30)\n",
    "feat2=torch.zeros(12,10)\n",
    "for i in range(12):\n",
    "    vol,label=testloader.dataset[i]\n",
    "    feature1,feature2=show(vol)\n",
    "    for j in range(30):\n",
    "        if j<10:\n",
    "            feat2[i,j]=feature2[j].item()\n",
    "        feat1[i,j]=feature1[j].item()\n",
    "\n",
    "showTensor(feat1)\n",
    "showTensor(feat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First convolution layer feature visualisation in 3D\n",
    "class VoxNet_feat_conv1(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_shape=(32, 32, 32)): \n",
    "        super(VoxNet_feat_conv1, self).__init__()\n",
    "        self.conv1=torch.nn.Conv3d(1,32,5,2)\n",
    "        self.conv = torch.nn.Sequential(torch.nn.LeakyReLU(),\n",
    "                                       torch.nn.Dropout(p=0.2),\n",
    "                                       torch.nn.Conv3d(32, 32, 3),\n",
    "                                       torch.nn.LeakyReLU(),\n",
    "                                       torch.nn.MaxPool3d(2),\n",
    "                                       torch.nn.Dropout(p=0.3)\n",
    "                                       \n",
    "        )\n",
    "        self.fc1=torch.nn.Linear(32* 6 * 6 * 6, 128)\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.4),\n",
    "            torch.nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0],1,32,32,32)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "cuda=True\n",
    "net1 = VoxNet_feat_conv1(num_classes=num_classes)\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print(\"using cuda\")\n",
    "    net.cuda()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=learning_rate)\n",
    "Utilitaires.train(net, optimizer, trainloader, testloader, criterion,  n_epoch = 10,\n",
    "      train_acc_period = 10,\n",
    "      test_acc_period = 1000)\n",
    "Utilitaires.accuracy(net,testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Convolution features.\n",
    "\n",
    "vol,label=testloader.dataset[100] \n",
    "label=label.item()\n",
    "print(labels_anglais[label])\n",
    "vol = vol.view(1,1,32,32,32)\n",
    "vol = vol.type(torch.cuda.FloatTensor)\n",
    "vol = net1.conv1(vol).view(32,14,14,14)\n",
    "for i in range(32):\n",
    "    voli=vol[i]\n",
    "    voli=voli.view(49,56)\n",
    "    voli=voli.cpu()\n",
    "    showTensor(voli)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
